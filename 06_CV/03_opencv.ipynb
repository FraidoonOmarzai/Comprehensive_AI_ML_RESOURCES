{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV In Depth\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) is an open-source computer vision and machine learning software library. It contains more than 2500 optimized algorithms, which can be used for various tasks such as detecting and recognizing faces, identifying objects, classifying human actions in videos, tracking camera movements, tracking moving objects, extracting 3D models of objects, and much more.\n",
    "\n",
    "![alt text](../Images/cv/opencv.png)\n",
    "\n",
    "### Key Features of OpenCV\n",
    "\n",
    "1. **Image Processing**: OpenCV offers a wide range of tools for processing images, such as filtering, geometric transformations, color space conversions, histograms, and more.\n",
    "2. **Video Analysis**: Includes tools for processing and analyzing video files, capturing video from cameras, and more. It supports tasks like background subtraction, object detection, and tracking.\n",
    "3. **Object Detection**: OpenCV can be used for detecting various objects like faces, pedestrians, and cars in both images and videos using algorithms like Haar cascades, HOG (Histogram of Oriented Gradients), and deep learning-based detectors.\n",
    "4. **Machine Learning**: The library contains many algorithms for classification, regression, and clustering, including k-nearest neighbors, support vector machines, decision trees, random forests, k-means, and more.\n",
    "5. **Deep Learning**: OpenCV has support for deep learning frameworks such as TensorFlow, Torch/PyTorch, and Caffe. It can load pre-trained models and use them to perform tasks like image classification and object detection.\n",
    "6. **3D Vision**: OpenCV includes algorithms for stereo vision, structure from motion (SfM), and 3D reconstruction. It can be used to generate 3D models from images or video sequences.\n",
    "7. **Camera Calibration and 3D Reconstruction**: OpenCV can be used for calibrating cameras to correct lens distortion and for performing 3D reconstruction of objects and scenes.\n",
    "8. **Augmented Reality**: The library provides tools for building augmented reality applications, including functions for overlaying 3D models on images or video frames.\n",
    "\n",
    "### Installation\n",
    "\n",
    "You can install OpenCV in Python using pip:\n",
    "\n",
    "```bash\n",
    "pip install opencv-python\n",
    "```\n",
    "\n",
    "For additional functionality (like support for reading and writing certain file formats), you may also want to install:\n",
    "\n",
    "```bash\n",
    "pip install opencv-python-headless\n",
    "pip install opencv-contrib-python\n",
    "```\n",
    "\n",
    "## Usages Of OpenCV\n",
    "![alt text](../Images/cv/opencv1.png)\n",
    "\n",
    "### 1. Image Basic With OpenCV\n",
    "\n",
    "- **Reading, Resize, Flip, and Displaying an Image**\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "# Resize the image\n",
    "image = cv2.resize(image, (224,224))\n",
    "\n",
    "# Flip the image\n",
    "image = cv2.flip(image, 0) # 0 to flip vertically\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "- **Converting an Image to Grayscale and RGB**\n",
    "\n",
    "```python\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Convert the image to RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "```\n",
    "\n",
    "- **Drawing on Image**\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a blank image\n",
    "blank_img = np.zeros(shape=(512,512,3),dtype=np.int16)\n",
    "\n",
    "# Draw rectangle on image\n",
    "cv2.rectangle(blank_img,pt1=(384,0),pt2=(510,128),color=(0,255,0),thickness=5)\n",
    "\n",
    "# Draw circle on image\n",
    "cv2.circle(img=blank_img, center=(100,100), radius=50, color=(255,0,0), thickness=5)\n",
    "\n",
    "# Draw line on image\n",
    "cv2.line(blank_img,pt1=(0,0),pt2=(511,511),color=(102, 255, 255),thickness=5)\n",
    "\n",
    "# Put text on image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(blank_img,\n",
    "\t\t\t\t\t\ttext='Hello',\n",
    "\t\t\t\t\t\torg=(10,500), \n",
    "\t\t\t\t\t\tfontFace=font,\n",
    "\t\t\t\t\t\tfontScale= 4,\n",
    "\t\t\t\t\t\tcolor=(255,255,255),\n",
    "\t\t\t\t\t\tthickness=2,\n",
    "\t\t\t\t\t\tlineType=cv2.LINE_AA)\n",
    "\t\t\t\t\t\t\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(blank_img)\n",
    "```\n",
    "\n",
    "### 2. Image Preprocessing With OpenCV\n",
    "\n",
    "- Is a method to perform some operations on image, in order to get an enhanced (improved) image or to extract some useful information from it.\n",
    "\n",
    "- **HSL and HSV:** HSL (Hue, Saturation, Lightness) and HSV (Hue, Saturation, Value) are alternative representations of the RGB color model. OpenCV can convert images between different color spaces.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "def color_space_conversion():\n",
    "    img = cv2.imread('image.jpg')\n",
    "\n",
    "    # Convert BGR to HSL\n",
    "    hsl_img = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    cv2.imshow('HSL Image', hsl_img)\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('HSV Image', hsv_img)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    color_space_conversion()\n",
    "```\n",
    "\n",
    "- **Blending Image:** Blending combines two images using a specific weight for each image. The result is a weighted sum of the two images.\n",
    "\n",
    "```python\n",
    "def blend_images():\n",
    "    img1 = cv2.imread('image1.jpg')\n",
    "    img2 = cv2.imread('image2.jpg')\n",
    "\n",
    "    # Resize images to the same size\n",
    "    img1 = cv2.resize(img1, (500, 500))\n",
    "    img2 = cv2.resize(img2, (500, 500))\n",
    "\n",
    "    blended = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)\n",
    "    cv2.imshow('Blended Image', blended)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    blend_images()\n",
    "```\n",
    "\n",
    "- **Image Threshold:** Thresholding is used to create a binary image from a grayscale image. OpenCV provides several types of thresholding. It is typically done in order to separate object or foreground pixels form background pixels to aid in image preprocessing.\n",
    "\n",
    "```python\n",
    "def image_threshold():\n",
    "    img = cv2.imread('image.jpg', 0)  # Load as grayscale\n",
    "\n",
    "    _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow('Binary Image', binary)\n",
    "\n",
    "    adaptive_mean = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    cv2.imshow('Adaptive Mean Thresholding', adaptive_mean)\n",
    "\n",
    "    adaptive_gaussian = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    cv2.imshow('Adaptive Gaussian Thresholding', adaptive_gaussian)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_threshold()\n",
    "    \n",
    "# 1. cv2.THRESH_BINARY\n",
    "# 2. cv2.THRESH_BINARY_INV\n",
    "# 3. cv2.THRESH_TRUNC\n",
    "# 4. cv2.THRESH_TOZERO\n",
    "# 5. cv2.THRESH_TOZERO_INV\n",
    "```\n",
    "\n",
    "- **Blurring or Smoothing:** Blurring is used to reduce noise and detail in an image.\n",
    "\n",
    "```python\n",
    "def blur_image():\n",
    "    img = cv2.imread('image.jpg')\n",
    "\n",
    "    # Apply different types of blurring\n",
    "    average_blur = cv2.blur(img, (5, 5))\n",
    "    cv2.imshow('Average Blurring', average_blur)\n",
    "\n",
    "    gaussian_blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    cv2.imshow('Gaussian Blurring', gaussian_blur)\n",
    "\n",
    "    median_blur = cv2.medianBlur(img, 5)\n",
    "    cv2.imshow('Median Blurring', median_blur)\n",
    "\n",
    "    bilateral_blur = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    cv2.imshow('Bilateral Blurring', bilateral_blur)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    blur_image()\n",
    "```\n",
    "\n",
    "- **Morphological Operation:** Morphological operations apply structuring elements to an image. Common operations include dilation, erosion, opening, and closing. It is used to shapes and structures inside of images. We can use it to increase the size of object in images as well as decrease them.\n",
    "\n",
    "```python\n",
    "def morphological_operations():\n",
    "    img = cv2.imread('image.jpg', 0)  # Load as grayscale\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "    dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "    cv2.imshow('Dilation', dilation)\n",
    "\n",
    "    erosion = cv2.erode(img, kernel, iterations=1)\n",
    "    cv2.imshow('Erosion', erosion)\n",
    "\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow('Opening', opening)\n",
    "\n",
    "    closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imshow('Closing', closing)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    morphological_operations()\n",
    "```\n",
    "\n",
    "- **Gradients:** Gradients are used to find edges in an image. Common methods include Sobel, Scharr, and Laplacian.\n",
    "\n",
    "```python\n",
    "def image_gradients():\n",
    "    img = cv2.imread('image.jpg', 0)  # Load as grayscale\n",
    "\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "\n",
    "    cv2.imshow('Sobel X', sobelx)\n",
    "    cv2.imshow('Sobel Y', sobely)\n",
    "    cv2.imshow('Laplacian', laplacian)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_gradients()\n",
    "```\n",
    "\n",
    "- **Histogram:** Histograms are used to represent the distribution of pixel intensities in an image. They can be used for contrast adjustment, thresholding, and more.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def image_histogram():\n",
    "    img = cv2.imread('image.jpg', 0)  # Load as grayscale\n",
    "\n",
    "    # Calculate histogram\n",
    "    hist = cv2.calcHist([img],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tchannels=[0],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmask=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\thistSize=[256],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tranges=[0,256])\n",
    "\n",
    "    # Plot histogram\n",
    "    plt.figure()\n",
    "    plt.title('Grayscale Histogram')\n",
    "    plt.xlabel('Bins')\n",
    "    plt.ylabel('# of Pixels')\n",
    "    plt.plot(hist)\n",
    "    plt.xlim([0, 256])\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_histogram()\n",
    "```\n",
    "\n",
    "### 3. Video Basic With OpenCV\n",
    "\n",
    "```python\n",
    "##############################Connect To Camera#############################\n",
    "import cv2\n",
    "\n",
    "# Connects to your computer's default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    \n",
    "    # This command let's us quit with the \"q\" button on a keyboard.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture and destroy the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "```python\n",
    "########################Writing a Video Stream to File########################\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Automatically grab width and height from video feed\n",
    "# (returns float which we need to convert to integer for later on!)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# MACOS AND LINUX: *'XVID' (MacOS users may want to try VIDX as well just in case)\n",
    "# WINDOWS *'DIVX'\n",
    "writer = cv2.VideoWriter('../DATA/student_capture.mp4', cv2.VideoWriter_fourcc(*'DIVX'),25, (width, height))\n",
    "\n",
    "## This loop keeps recording until you hit Q or escape the window\n",
    "## You may want to instead use some sort of timer, like from time import sleep and then just record for 5 seconds.\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    \n",
    "    # Write the video\n",
    "    writer.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    # This command let's us quit with the \"q\" button on a keyboard.\n",
    "    # Simply pressing X on the window won't work!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "        \n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "```python\n",
    "##############################Open Recorded Video###############################\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Same command function as streaming, its just now we pass in the file path, nice!\n",
    "cap = cv2.VideoCapture('../DATA/video_capture.mp4')\n",
    "\n",
    "# FRAMES PER SECOND FOR VIDEO\n",
    "fps = 25\n",
    "\n",
    "# Always a good idea to check if the video was acutally there\n",
    "# If you get an error at thsi step, triple check your file path!!\n",
    "if cap.isOpened()== False: \n",
    "    print(\"Error opening the video file. Please double check your file path for typos. Or move the movie file to the same location as this script/notebook\")\n",
    "    \n",
    "# While the video is opened\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Read the video file.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If we got frames, show them.\n",
    "    if ret == True:\n",
    "        \n",
    "         # Display the frame at same frame rate of recording\n",
    "        # Watch lecture video for full explanation\n",
    "        time.sleep(1/fps)\n",
    "        cv2.imshow('frame',frame)\n",
    " \n",
    "        # Press q to quit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            \n",
    "            break\n",
    " \n",
    "    # Or automatically break this whole loop if the video is over.\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "### 4. Object Detection With OpenCV\n",
    "\n",
    "- **Template Matching:** Template Matching is a technique to find parts of an image that match a template image.\n",
    "\n",
    "```python\n",
    "# The Full Image to Search\n",
    "full = cv2.imread('dog.jpg')\n",
    "full = cv2.cvtColor(full, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# The Template to Match\n",
    "face= cv2.imread('dog_face.jpg')\n",
    "face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "# Note how we are using strings, later on we'll use the eval() function to convert to function\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR','cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for m in methods:\n",
    "    \n",
    "    # Create a copy of the image\n",
    "    full_copy = full.copy()\n",
    "    \n",
    "    # Get the actual function instead of the string\n",
    "    method = eval(m)\n",
    "\n",
    "    # Apply template Matching with the method\n",
    "    res = cv2.matchTemplate(full_copy,face,method)\n",
    "    \n",
    "    # Grab the Max and Min values, plus their locations\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    # Set up drawing of Rectangle\n",
    "    \n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    # Notice the coloring on the last 2 left hand side images.\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc    \n",
    "    else:\n",
    "        top_left = max_loc\n",
    "        \n",
    "    # Assign the Bottom Right of the rectangle\n",
    "    bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "\n",
    "    # Draw the Red Rectangle\n",
    "    cv2.rectangle(full_copy,top_left, bottom_right, 255, 10)\n",
    "\n",
    "    # Plot the Images\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(res)\n",
    "    plt.title('Result of Template Matching')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(full_copy)\n",
    "    plt.title('Detected Point')\n",
    "    plt.suptitle(m)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "```\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def template_matching():\n",
    "    img = cv2.imread('image.jpg')\n",
    "    template = cv2.imread('template.jpg', 0)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    w, h = template.shape[::-1]\n",
    "\n",
    "    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "    threshold = 0.8\n",
    "    loc = np.where(res >= threshold)\n",
    "\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Detected', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    template_matching()\n",
    "```\n",
    "\n",
    "- **Corner Detection:** Corner Detection is used to find the corners within an image. One popular method is the Harris Corner Detection.\n",
    "\n",
    "```python\n",
    "def corner_detection():\n",
    "    img = cv2.imread('image.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "\n",
    "    corners = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    corners = cv2.dilate(corners, None)\n",
    "\n",
    "    img[corners > 0.01 * corners.max()] = [0, 0, 255]\n",
    "\n",
    "    cv2.imshow('Corners', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    corner_detection()\n",
    "```\n",
    "\n",
    "- **Edge Detection:** Edge Detection is used to detect the edges within an image. The Canny Edge Detector is a popular edge detection algorithm.\n",
    "\n",
    "```python\n",
    "def edge_detection():\n",
    "    img = cv2.imread('image.jpg', 0)\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "    cv2.imshow('Edges', edges)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    edge_detection()\n",
    "```\n",
    "\n",
    "- **Grid Detection:** Grid detection can be achieved using a combination of edge detection and Hough Line Transform.\n",
    "\n",
    "```python\n",
    "def grid_detection():\n",
    "    img = cv2.imread('grid.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    \n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "\n",
    "    for rho, theta in lines[:, 0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Grid Detection', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_detection()\n",
    "```\n",
    "\n",
    "```python\n",
    "found, corners = cv2.findChessboardCorners(img,(7,7))\n",
    "\n",
    "img_copy = img.copy()\n",
    "cv2.drawChessboardCorners(img_copy, (7, 7), corners, found)\n",
    "plt.imshow(img_copy)\n",
    "\n",
    "found, corners = cv2.findCirclesGrid(dots, (10,10), cv2.CALIB_CB_SYMMETRIC_GRID)\n",
    "dbg_image_circles = dots.copy()\n",
    "cv2.drawChessboardCorners(dbg_image_circles, (10, 10), corners, found)\n",
    "plt.imshow(dbg_image_circles)\n",
    "```\n",
    "\n",
    "- **Contours:** Contours are curves joining all the continuous points along a boundary having the same color or intensity.\n",
    "\n",
    "```python\n",
    "def find_contours():\n",
    "    img = cv2.imread('image.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    cv2.imshow('Contours', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_contours()\n",
    "```\n",
    "\n",
    "- **Feature Matching:** Feature matching involves detecting key points and descriptors in an image and finding similar features in another image.\n",
    "\n",
    "```python\n",
    "def feature_matching():\n",
    "    img1 = cv2.imread('image1.jpg', 0)\n",
    "    img2 = cv2.imread('image2.jpg', 0)\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    cv2.imshow('Feature Matching', img3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    feature_matching()\n",
    "```\n",
    "\n",
    "- **Watershed Algorithm:** The Watershed Algorithm is used for image segmentation. It treats pixels values as a topographic surface.\n",
    "\n",
    "```python\n",
    "def watershed_algorithm():\n",
    "    img = cv2.imread('image.jpg')\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(img, markers)\n",
    "    img[markers == -1] = [255, 0, 0]\n",
    "\n",
    "    cv2.imshow('Watershed', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    watershed_algorithm()\n",
    "```\n",
    "\n",
    "- **Face Detection:** Detect a face in an image.\n",
    "\n",
    "```python\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def detect_face(img):\n",
    "  \n",
    "    face_img = img.copy()\n",
    "  \n",
    "    face_rects = face_cascade.detectMultiScale(face_img) \n",
    "    \n",
    "    for (x,y,w,h) in face_rects: \n",
    "        cv2.rectangle(face_img, (x,y), (x+w,y+h), (255,255,255), 10) \n",
    "        \n",
    "    return face_img\n",
    "    \n",
    "img = cv2.imread('img.jpg',0)\n",
    "result = detect_face(img)\n",
    "plt.imshow(result, cmap='gray')\n",
    "```\n",
    "\n",
    "### 5. Object Tracking With OpenCV\n",
    "\n",
    "1. **Optical Flow** is useful for tracking feature points across frames.\n",
    "2. **Mean Shift** is good for tracking objects with a known appearance model.\n",
    "3. **Cam Shift** improves upon Mean Shift by dynamically adjusting the window size and orientation.\n",
    "4. **Tracking API** provides a high-level interface to various advanced tracking algorithms.\n",
    "- **Optical flow:** is the pattern of apparent motion of objects, surfaces, and edges in a visual scene. OpenCV provides several methods for optical flow. Here, we'll use the Lucas-Kanade method.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def optical_flow():\n",
    "    cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    # Take first frame\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    # Select a ROI\n",
    "    bbox = cv2.selectROI(\"Frame\", old_frame, fromCenter=False, showCrosshair=True)\n",
    "    x, y, w, h = bbox\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray[y:y+h, x:x+w], mask=None, **lk_params)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        # Draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "\n",
    "        cv2.imshow('frame', img)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "        # Update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optical_flow()\n",
    "```\n",
    "\n",
    "- **Mean Shift:** is a clustering algorithm that can be used for object tracking. OpenCV provides the `cv2.meanShift` function to perform Mean Shift tracking.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "def mean_shift():\n",
    "    cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    # Take first frame of the video\n",
    "    ret, frame = cap.read()\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, (0, 60, 32), (180, 255, 255))\n",
    "\n",
    "        ret, bbox = cv2.meanShift(mask, bbox, term_crit)\n",
    "\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.imshow('MeanShift Tracking', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mean_shift()\n",
    "```\n",
    "\n",
    "- **Cam Shift (Continuously Adaptive Mean Shift):** is an enhanced version of Mean Shift, and it adjusts the window size and orientation.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "def cam_shift():\n",
    "    cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    # Take first frame of the video\n",
    "    ret, frame = cap.read()\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "    term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, (0, 60, 32), (180, 255, 255))\n",
    "\n",
    "        ret, bbox = cv2.CamShift(mask, bbox, term_crit)\n",
    "\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "        cv2.imshow('CamShift Tracking', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cam_shift()\n",
    "```\n",
    "\n",
    "**Tracking API (Built-in with OpenCV):** OpenCV provides a tracking API that supports multiple tracking algorithms, including BOOSTING, MIL, KCF, TLD, MEDIANFLOW, GOTURN, MOSSE, and CSRT.\n",
    "\n",
    "Here is an example using the CSRT tracker:\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "def tracking_api():\n",
    "    cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, frame = cap.read()\n",
    "    bbox = cv2.selectROI(frame, False)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Update tracker\n",
    "        success, bbox = tracker.update(frame)\n",
    "\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Tracking failure detected\", (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow('Tracking API', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tracking_api()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center> CNN Architectures </h1>\n",
    "\n",
    "![alt text](../Images/dl/cnn_archi.png)\n",
    "\n",
    "## 1. LeNet\n",
    "\n",
    "- First CNN architecture\n",
    "- Hello word of deep learning\n",
    "- 60k parameters\n",
    "- Applied on handwritten digit recognition task\n",
    "- Activation function in hidden layer: sigmoid/tanh\n",
    "- Activation function in output layer: softmax\n",
    "- Pooling: average pooling\n",
    "\n",
    "![alt text](../Images/dl/lenet.png)\n",
    "\n",
    "## 2. Alex Net\n",
    "\n",
    "- The architecture that popularized CNN\n",
    "- Similar to LeNet but more deeper\n",
    "- Winner of imageNet large-scale visual recognition challenge (ILSVRC) in 2012\n",
    "- To reduce overfitting authors used dropout 50% and data augmentation\n",
    "- Activation function in hidden layer: Relu\n",
    "- Activation function in output layer: softmax\n",
    "- Pooling: Max pooling\n",
    "\n",
    "![alt text](../Images/dl/alexnet.png)\n",
    "\n",
    "## 3. ZFNet\n",
    "\n",
    "![alt text](../Images/dl/zfnet.png)\n",
    "\n",
    "## 4. GoogleNet\n",
    "\n",
    "- Winner of ImageNet large-scale visual recognition challenge (ILSVRC) in 2014\n",
    "- Their architecture consisted of 22-layers deep CNN but reduced the number of parameters from 60 million (AlexNet) to 4 million\n",
    "- The network was much deeper than the previous CNN. This was made possible by subnetworks called inception modules\n",
    "- The local response normalization layer was used to ensure that the previous layers learned various features\n",
    "- Consist of nine inception modules\n",
    "- Dropout 40%\n",
    "- Activation function in hidden layer: Relu\n",
    "- Activation function in output layer: Softmax\n",
    "\n",
    "![alt text](../Images/dl/googlenet.png)\n",
    "\n",
    "## 5. VGGNet\n",
    "\n",
    "- The runner-up in the ILSVRC 2014 challenges\n",
    "- Classicical architecture\n",
    "- Much deeper\n",
    "- Activation function in hidden layer: Relu\n",
    "- Activation function in output layer: Softmax\n",
    "\n",
    "![alt text](../Images/dl/vgg.png)\n",
    "\n",
    "## 6. ResNet\n",
    "\n",
    "- Winner of ImageNet large scale visual recognition challenge (ILSVRC) in 2015\n",
    "- The key to being able to train such a deep network is to use skip connections (shortcut connections)\n",
    "\n",
    "![alt text](../Images/dl/resnet.png)\n",
    "\n",
    "## 7. Inception Network\n",
    "\n",
    "- If we do not know to add which size of filters; 1X1, 3X3 or 5X5 we can add all and use them together.\n",
    "- We apply 1X1 conv to shrink the number of channel and it will help to reduce the computation cost.\n",
    "\n",
    "![alt text](../Images/dl/inception_module.png)\n",
    "\n",
    "## 8. 1x1 Convolution (Network in network)\n",
    "\n",
    "- Reduce the number of depth channels\n",
    "\n",
    "![alt text](../Images/dl/1x1conv.png)\n",
    "\n",
    "## 9. Mobile Net\n",
    "\n",
    "- Low computational cost at deployment\n",
    "- We use depth-wise separable convolution which is more simpler than normal convolution\n",
    "\n",
    "![alt text](../Images/dl/mobiill.png)\n",
    "![alt text](../Images/dl/mobilenetv1.png)\n",
    "\n",
    "## 10. Unet\n",
    "\n",
    "![alt text](../Images/dl/unet.png)\n",
    "\n",
    "## EfficientNet\n",
    "\n",
    "![alt text](../Images/dl/efficient.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
